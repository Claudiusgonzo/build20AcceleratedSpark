{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Queries on a Single DF from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1586146063972_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://pipedreamhd.azurehdinsight.net/yarnui/hn/proxy/application_1586146063972_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn4-pipedr.bh4dzsewnzne3doz2hewdd4akd.dx.internal.cloudapp.net:30060/node/containerlogs/container_1586146063972_0005_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxi_file_loc=\"wasb://yellow@pipedreamdemo/taxi_data/yellow_tripdata_2019-12.csv\"\n",
    "schema_cols = \"VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxi_orig_schema = (\n",
    "    StructType()\n",
    "    .add(\"VendorID\", IntegerType())\n",
    "    .add(\"tpep_pickup_datetime\", TimestampType())\n",
    "    .add(\"tpep_dropoff_datetime\", TimestampType())\n",
    "    .add(\"passenger_count\", IntegerType())\n",
    "    .add(\"trip_distance\", DoubleType())\n",
    "    .add(\"RatecodeID\", IntegerType())\n",
    "    .add(\"store_and_fwd_flag\", StringType())\n",
    "    .add(\"PULocationID\", IntegerType())\n",
    "    .add(\"DOLocationID\", IntegerType())\n",
    "    .add(\"payment_type\", IntegerType())\n",
    "    .add(\"fare_amount\", DoubleType())\n",
    "    .add(\"extra\", DoubleType())\n",
    "    .add(\"mta_tax\", DoubleType())\n",
    "    .add(\"tip_amount\", DoubleType())\n",
    "    .add(\"tolls_amount\", DoubleType())\n",
    "    .add(\"improvement_surcharge\", DoubleType())\n",
    "    .add(\"total_amount\", DoubleType())\n",
    "    .add(\"congestion_surcharge\", DoubleType())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Interpreter died:\n",
      "\n",
      "/usr/hdp/current/spark2-client/python/pyspark/context.py:261: RuntimeWarning: Failed to add file [file:/usr/hdp/current/spark2-client/python/lib/pyspark.zip] speficied in 'spark.submit.pyFiles' to Python path:\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/tmp\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/spark-b02c8e03-a6a6-40a4-a364-0e86f485fb21/userFiles-6c84950d-1e7c-4433-af02-3d504a2657da\n",
      "  /usr/hdp/current/spark2-client/python\n",
      "  /usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/pyspark.zip\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/py4j-0.10.7-src.zip\n",
      "  /usr/bin/anaconda/lib/python27.zip\n",
      "  /usr/bin/anaconda/lib/python2.7\n",
      "  /usr/bin/anaconda/lib/python2.7/plat-linux2\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-tk\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-old\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-dynload\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages/Sphinx-1.4.6-py2.7.egg\n",
      "  /var/lib/.jupyter/jupyterazure\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg\n",
      "  RuntimeWarning)\n",
      "/usr/hdp/current/spark2-client/python/pyspark/context.py:261: RuntimeWarning: Failed to add file [file:/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip] speficied in 'spark.submit.pyFiles' to Python path:\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/tmp\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/spark-b02c8e03-a6a6-40a4-a364-0e86f485fb21/userFiles-6c84950d-1e7c-4433-af02-3d504a2657da\n",
      "  /usr/hdp/current/spark2-client/python\n",
      "  /usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/pyspark.zip\n",
      "  /mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/py4j-0.10.7-src.zip\n",
      "  /usr/bin/anaconda/lib/python27.zip\n",
      "  /usr/bin/anaconda/lib/python2.7\n",
      "  /usr/bin/anaconda/lib/python2.7/plat-linux2\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-tk\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-old\n",
      "  /usr/bin/anaconda/lib/python2.7/lib-dynload\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages/Sphinx-1.4.6-py2.7.egg\n",
      "  /var/lib/.jupyter/jupyterazure\n",
      "  /usr/bin/anaconda/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg\n",
      "  RuntimeWarning)\n",
      "\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/tmp/1656805614047440300\", line 318, in execute_request\n",
      "    result = node.execute()\n",
      "  File \"/mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1586146063972_0005/container_1586146063972_0005_01_000001/tmp/1656805614047440300\", line 233, in execute\n",
      "    raise ExecutionError(sys.exc_info())\n",
      "ExecutionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_train_df = spark.read.schema(taxi_orig_schema).csv(taxi_file_loc, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "taxi_train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+"
     ]
    }
   ],
   "source": [
    "taxi_train_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxi_train_df.createOrReplaceTempView('nyyellowtaxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  total|\n",
      "+-------+\n",
      "|6896317|\n",
      "+-------+"
     ]
    }
   ],
   "source": [
    "\n",
    "count_df = spark.sql(\"select count(*) as total from nyyellowtaxi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+-------+\n",
      "|passenger_count|year|  total|\n",
      "+---------------+----+-------+\n",
      "|              5|2009|      6|\n",
      "|              6|2019| 147923|\n",
      "|              9|2019|     16|\n",
      "|              4|2019| 164921|\n",
      "|              8|2019|     18|\n",
      "|              5|2020|      1|\n",
      "|              4|2009|      2|\n",
      "|              6|2008|      1|\n",
      "|              4|2008|      4|\n",
      "|              1|2058|      3|\n",
      "|              5|2019| 244875|\n",
      "|              1|2009|     16|\n",
      "|           null|2019|  51018|\n",
      "|              3|2019| 302987|\n",
      "|              2|2008|      6|\n",
      "|              1|2019|4783228|\n",
      "|              1|2008|      8|\n",
      "|              3|2020|     12|\n",
      "|              4|2020|      4|\n",
      "|              1|2026|      1|\n",
      "+---------------+----+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "psg_count_dist = spark.sql(\"SELECT passenger_count, \\\n",
    "    year(tpep_pickup_datetime) year, count(*) total FROM nyyellowtaxi GROUP BY passenger_count, year(tpep_pickup_datetime)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_fare_psg_count = spark.sql(\"SELECT passenger_count, \\\n",
    "                                avg(total_amount) avg_fare FROM nyyellowtaxi GROUP BY passenger_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|passenger_count|          avg_fare|\n",
      "+---------------+------------------+\n",
      "|           null| 38.10385452193327|\n",
      "|              1|  19.2689940821399|\n",
      "|              6|19.365102653367924|\n",
      "|              3|20.025870953485427|\n",
      "|              5| 19.35781789152236|\n",
      "|              9| 72.15124999999999|\n",
      "|              4|20.576281717809266|\n",
      "|              8| 94.81166666666665|\n",
      "|              7| 61.69222222222221|\n",
      "|              2| 20.35205234127457|\n",
      "|              0| 18.94103797144808|\n",
      "+---------------+------------------+"
     ]
    }
   ],
   "source": [
    "avg_fare_psg_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psg_year_count = spark.sql(\"SELECT passenger_count, \\\n",
    "                    year(tpep_pickup_datetime) trip_year, \\\n",
    "                    round(trip_distance) distance, \\\n",
    "                    count(*) trips \\\n",
    "                    FROM nyyellowtaxi \\\n",
    "                    GROUP BY passenger_count, \\\n",
    "                        year(tpep_pickup_datetime), round(trip_distance) ORDER BY trip_year, trips desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------+-----+\n",
      "|passenger_count|trip_year|distance|trips|\n",
      "+---------------+---------+--------+-----+\n",
      "|              1|     2008|     1.0|    3|\n",
      "|              4|     2008|     1.0|    2|\n",
      "|              3|     2008|     1.0|    2|\n",
      "|              3|     2008|     3.0|    2|\n",
      "|              1|     2008|     0.0|    2|\n",
      "|              2|     2008|     1.0|    2|\n",
      "|              3|     2008|     0.0|    1|\n",
      "|              1|     2008|    10.0|    1|\n",
      "|              3|     2008|     4.0|    1|\n",
      "|              2|     2008|     8.0|    1|\n",
      "|              1|     2008|    12.0|    1|\n",
      "|              6|     2008|    18.0|    1|\n",
      "|              5|     2008|     0.0|    1|\n",
      "|              2|     2008|     3.0|    1|\n",
      "|              2|     2008|     0.0|    1|\n",
      "|              2|     2008|    17.0|    1|\n",
      "|              5|     2008|     1.0|    1|\n",
      "|              4|     2008|     2.0|    1|\n",
      "|              5|     2008|     2.0|    1|\n",
      "|              1|     2008|     8.0|    1|\n",
      "+---------------+---------+--------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "psg_year_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
